{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 该算法首先将所有点作为一个簇，然后将该簇一分为二，之后选择其中一个簇继续进行划分，选择的标准取决于，该簇一分为二后可以最大程度地降低SSE的值。\n",
    "---\n",
    "### 伪代码：\n",
    "```python\n",
    "将所有点看成一个簇\n",
    "当簇的数量小于k时：\n",
    "    对于每一个簇：\n",
    "        计算总误差SSE\n",
    "        在当前簇上进行k均值聚类（K=2）\n",
    "        计算将该簇一分为二后的总误差\n",
    "    选择使得误差最小的那个簇进行划分操作\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程序清单10-3 二分K-均值聚类算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要k均值聚类的所有函数，这里复制过来：\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def loadDataSet(filename):\n",
    "    \"\"\"数据加载函数\"\"\"\n",
    "    dataMat=[]\n",
    "    fr=open(filename)\n",
    "    for line in fr.readlines():\n",
    "        curLine=line.strip().split('\\t')\n",
    "        fline=list(map(float, curLine))\n",
    "        dataMat.append(fline)\n",
    "    return dataMat\n",
    "\n",
    "\n",
    "def distEclud(vecA,vecB):\n",
    "    \"\"\"计算两个向量之间的欧几里得距离\"\"\"\n",
    "    return np.sqrt(np.sum((vecA-vecB)**2))\n",
    "\n",
    "\n",
    "def randCent(dataSet,k):\n",
    "    \"\"\"初始化簇质心,k是随机生成的质心的个数\"\"\"\n",
    "    n=dataSet.shape[1]\n",
    "    cent=np.mat(np.zeros((k,n)))    # 初始化k个质心\n",
    "    for j in range(n):\n",
    "        minJ=dataSet[:,j].min()\n",
    "        maxJ=dataSet[:,j].max()\n",
    "        rangeJ=float(maxJ-minJ)    # 第j个特征的范围\n",
    "        cent[:,j]=minJ+rangeJ*np.random.rand(k,1)\n",
    "    return cent\n",
    "\n",
    "\n",
    "def kMeans(dataSet, k,distMeas=distEclud,createCent=randCent):\n",
    "    m=dataSet.shape[0]\n",
    "    clusterAssment=np.mat(np.zeros((m,2)))    # 第一列：每个样本所属的类标签；第二列：存储误差\n",
    "    center=createCent(dataSet,k)    # 随机初始化各个簇的质心\n",
    "    clusterChanged=True\n",
    "    \n",
    "    while clusterChanged:\n",
    "        clusterChanged=False\n",
    "        for i in range(m):    # 遍历每个样本，寻找其属于哪个中心（哪个簇）\n",
    "            minDist=np.inf\n",
    "            minIndex=-1\n",
    "            for j in range(k):   # 对每个质心，寻找距离该样本最短的质心\n",
    "                # 这里需要注意，datMat[0,:]\n",
    "                distJI = distEclud(center[j, :].A[0], dataSet[i, :].A[0])    # 注意，datMat[0,:]是一个二维的矩阵，需转换成向量\n",
    "                if distJI<minDist:\n",
    "                    minDist=distJI\n",
    "                    minIndex=j    # 更新该样本属于哪个中心\n",
    "            # 现在对于该样本已经找到了其属于哪个簇中心\n",
    "            if clusterAssment[i,0]!=minIndex:    # 样本所属的簇发生改变：\n",
    "                clusterChanged=True\n",
    "            clusterAssment[i,:]=minIndex,minDist**2    # 更新簇结果分配矩阵\n",
    "        # print(center)\n",
    "        \n",
    "        for c in range(k):\n",
    "            ptsInClust=dataSet[np.nonzero(clusterAssment[:,0].A==c)[0]]    # 获取属于簇c的所有样本点\n",
    "            center[c,:]=np.mean(ptsInClust,axis=0)    # 更新各个簇的质心\n",
    "            \n",
    "    return center,clusterAssment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biKmeans(dataSet:np.matrix,k:int,distMeas=distEclud):\n",
    "    m=dataSet.shape[0]\n",
    "    clusterAssignment=np.mat(np.zeros((m,2)))\n",
    "    center0=dataSet.mean(axis=0)    # 初始化聚类中心\n",
    "    centList=[center0]\n",
    "    \n",
    "    for j in range(m):\n",
    "        clusterAssignment[:,1]=distEclud(center0,dataSet[j,:])**2    # 这里的这个**2会报错吗\n",
    "        \n",
    "    while len(centList)<k:\n",
    "        lowestSSE=np.inf\n",
    "        for i in range(len(centList)):\n",
    "            # 获取该簇下的数据\n",
    "            ptsInCurrCenter=dataSet[np.nonzero(clusterAssignment[:,0]==i)[0],:]\n",
    "            # 对该簇下的数据进行k=2的kMeans聚类\n",
    "            centMat2,splitClustAss=kMeans(ptsInCurrCenter,k=2)    # 尝试划分当前簇\n",
    "            sseSplit=np.sum(splitClustAss[:,1],axis=0)    # 误差计算\n",
    "            # 计算不属于当前簇的其他样本（其实就是另一个簇）的总误差\n",
    "            sseNotSplit=np.sum(clusterAssignment[:,1][np.nonzero(clusterAssignment.A[:,0]!=i)[0]])\n",
    "            \n",
    "            if sseSplit+sseNotSplit<lowestSSE:\n",
    "                bestCentToSplit=i    # 更新最佳分裂簇\n",
    "                bestNewCents=centMat2    # 更新最佳簇中心点\n",
    "                bestClustAss=splitClustAss.copy()\n",
    "                lowestSSE=sseSplit+sseNotSplit    # 最小误差更新\n",
    "                \n",
    "                # 更新簇的分配结果\n",
    "                bestClustAss[np.nonzero(bestClustAss.A[:,0]==1)[0],0]=len(centList)\n",
    "                bestClustAss[np.nonzero(bestClustAss.A[:,0]==0)[0],0]=bestCentToSplit\n",
    "                centList[bestCentToSplit]=bestNewCents[0,:]\n",
    "                centList.append(bestNewCents[1,:])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69bb06a9fb724e3616bb36eae2c2891ed4de586fe76c0b350d4e65619dfe458e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
